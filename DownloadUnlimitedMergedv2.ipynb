{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DownloadUnlimitedMergedv2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVr2kFp2hgxD"
      },
      "source": [
        "### **README**\n",
        "\n",
        "# What this does\n",
        "\n",
        "This script allows you to download a single merged results tile with no row limit, as one `txt` file. Use at your own risk. Known limitations:\n",
        "\n",
        "- Script downloads a single merged tile, not an entire dashboard.\n",
        "- Script only allows for downloading a merge tile with 2 merged queries. Tiles with >2 queries will likely error or output misleading results. \n",
        "- Script may cause your computer to crash or slow. Why? \n",
        "  - It merges unlimited results by creating a pandas dataframe for each merged query, then using `pd.merge()`\n",
        "  - As a result, your computer has to hold each dataframe in memory (however large they may be), then create another dataframe with size `df1+df2` and also hold that in memory. \n",
        "\n",
        "\n",
        "# Notes\n",
        "`DownloadUnlimitedMerged_OneFile(dash_id, tile_title)` accepts 2 inputs:\n",
        "\n",
        "- `dash_id`(string) - the ID of the dashboard\n",
        "- `tile_title`(string) - the title of the merged results tile\n",
        "\n",
        "Output files will be named `tile_title.txt`.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "If using colab version, you will need to input your api url, client_id, and client_secret in the `## colab inputs ##` section. \n",
        "\n",
        "```\n",
        "os.environ['LOOKERSDK_BASE_URL'] = 'https://example.looker.com'\n",
        "os.environ['LOOKERSDK_API_VERSION'] = '3.1'\n",
        "os.environ['LOOKERSDK_CLIENT_ID'] = 'client id here'\n",
        "os.environ['LOOKERSDK_CLIENT_SECRET'] = 'client secret here'\n",
        "```\n",
        "\n",
        "If using python (local) version, these values should be set for the sdk per either an `.ini` file or as an environment variable. See Python SDK documentation for more information. https://pypi.org/project/looker-sdk/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGd0X7bi2rgh",
        "outputId": "73caffed-2178-49e9-d76c-9e889bda46e5"
      },
      "source": [
        "### colab specific ###\n",
        "# install the sdk\n",
        "!pip install looker-sdk\n",
        "# set environ variables\n",
        "import os\n",
        "\n",
        "## colab inputs ##\n",
        "os.environ['LOOKERSDK_BASE_URL'] = ''\n",
        "os.environ['LOOKERSDK_API_VERSION'] = '3.1'\n",
        "os.environ['LOOKERSDK_CLIENT_ID'] = ''\n",
        "os.environ['LOOKERSDK_CLIENT_SECRET'] = ''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: looker-sdk in /usr/local/lib/python3.7/dist-packages (21.4.0)\n",
            "Requirement already satisfied: attrs>=20.1.0; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from looker-sdk) (20.3.0)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.7/dist-packages (from looker-sdk) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from looker-sdk) (3.7.4.3)\n",
            "Requirement already satisfied: cattrs==1.1.2; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from looker-sdk) (1.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22->looker-sdk) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22->looker-sdk) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22->looker-sdk) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22->looker-sdk) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tVrT5pxulQU"
      },
      "source": [
        "# will need these for downloading the file from colab\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# auth stuff for download\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl4-Eu-k2v87"
      },
      "source": [
        "### import packages ###\n",
        "# import and init\n",
        "import looker_sdk\n",
        "sdk = looker_sdk.init31(\"looker.ini\")\n",
        "\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nh7DQOn2xhj"
      },
      "source": [
        "## inputs ##\n",
        "\n",
        "dash_id = ''\n",
        "tile_title = ''\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMyHlUUXBBp"
      },
      "source": [
        "# get merge query id from dashboard \n",
        "data = sdk.search_dashboard_elements(dashboard_id=dash_id, title=tile_title )\n",
        "mergeid = data[0].merge_result_id\n",
        "\n",
        "# get source query ids from merge query\n",
        "mergedata = sdk.merge_query(merge_query_id=mergeid)\n",
        "source_qs = mergedata.source_queries\n",
        "num_merged = len(source_qs)\n",
        "\n",
        "# init some lists\n",
        "listoffiles = []\n",
        "left_on = []\n",
        "right_on = []\n",
        "elements_needed = ['model','view','fields','filters','sorts','limit','query_timezone']\n",
        "lenneedd = len(elements_needed)\n",
        "\n",
        "# start god loop\n",
        "for x in range(num_merged): \n",
        "    final_body = {}  \n",
        "    # get raw query body\n",
        "    source_qids = source_qs[x].query_id\n",
        "    query_body = sdk.query(query_id=source_qids)\n",
        "    \n",
        "    # change limit to unlimited \n",
        "    query_body['limit'] = '-1'\n",
        "\n",
        "    # add needed elements in raw body to final body\n",
        "    for y in range(lenneedd):\n",
        "      try:\n",
        "          new_el = query_body[elements_needed[y]]\n",
        "      except:\n",
        "          y+=1\n",
        "      else:\n",
        "          final_body[elements_needed[y]] = new_el\n",
        "\n",
        "    # run unlimited query\n",
        "    resultset = sdk.run_inline_query('csv', final_body)\n",
        "    \n",
        "    # save files in the format 'Fooq1.csv` and record name in list\n",
        "    with open(tile_title + 'q'+str(x)+'.csv', 'w') as file:\n",
        "              file.write(resultset)\n",
        "    listoffiles.append(tile_title + 'q'+str(x)+'.csv')\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm86Qk0mfeLp"
      },
      "source": [
        "# get join strings\n",
        "lefton = mergedata.source_queries[1].merge_fields[0].source_field_name\n",
        "righton = mergedata.source_queries[1].merge_fields[0].field_name\n",
        "\n",
        "# normalize\n",
        "lefton = lefton.lower()\n",
        "righton = righton.lower()\n",
        "lefton = lefton.replace('.','')\n",
        "righton = righton.replace('.','')\n",
        "lefton = lefton.replace('_','')\n",
        "righton = righton.replace('_','')\n",
        "lefton = lefton.replace(' ','')\n",
        "righton = righton.replace(' ','')\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khs1eQEWFpjH",
        "outputId": "05f9b2d4-67ae-49da-b885-2b2c98c30c38"
      },
      "source": [
        "# probably unnecessary\n",
        "merge = 'null'\n",
        "\n",
        "# create dataframe 1 & normalize\n",
        "df1 = pd.read_table(listoffiles[0], delimiter =\",\",engine='python')\n",
        "df1.columns = df1.columns.str.lower()\n",
        "df1.columns = df1.columns.str.replace('.','')\n",
        "df1.columns = df1.columns.str.replace('_','')\n",
        "df1.columns = df1.columns.str.replace(' ','')\n",
        "\n",
        "# create dataframe 2 & normalize\n",
        "df2 = pd.read_table(listoffiles[1], delimiter =\",\",engine='python')\n",
        "df2.columns = df2.columns.str.lower()\n",
        "df2.columns = df2.columns.str.replace('.','')\n",
        "df2.columns = df2.columns.str.replace('_','')\n",
        "df2.columns = df2.columns.str.replace(' ','')\n",
        "\n",
        "# the merge. left just like merged results\n",
        "merge = pd.merge(df1, df2, \n",
        "                   left_on= lefton , \n",
        "                   right_on= righton ,\n",
        "                   how='left')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['ordersstatus', 'ordersuserid', 'ordersid', 'orderscount'], dtype='object')\n",
            "Index(['usersid', 'usersstate', 'userscount'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2aW4fzFaLUNH",
        "outputId": "5edc03f9-d094-4705-ab8c-53c7fbd3b562"
      },
      "source": [
        "# create txt file\n",
        "merge.to_csv(tile_title+'.txt',\n",
        "      sep=',',\n",
        "      header=False,\n",
        "      index=False,\n",
        "      quoting=csv.QUOTE_ALL,\n",
        "      quotechar='\"',\n",
        "      doublequote=True,\n",
        "      line_terminator='\\n')\n",
        "\n",
        "# colab only\n",
        "from google.colab import files \n",
        "files.download('merge.txt')\n",
        "# end colab"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e50391c4-90c2-4e93-888c-51b824b779b7\", \"merge.txt\", 1676730)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}